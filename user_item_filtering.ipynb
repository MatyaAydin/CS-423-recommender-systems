{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15712, 18905)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load df\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "\n",
    "book_ids = df_train['book_id'].unique()\n",
    "user_ids = df_train['user_id'].unique()\n",
    "\n",
    "nb_books = len(book_ids)\n",
    "nb_users = len(user_ids)\n",
    "\n",
    "nb_books, nb_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_idx = {ids: i for i,ids in enumerate(book_ids)}\n",
    "user_idx = {ids: i for i,ids in enumerate(user_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.zeros((nb_users, nb_books))\n",
    "\n",
    "#inspired from code in week 5 exercise\n",
    "for line in df_train.itertuples():\n",
    "    X[user_idx[line[2]], book_idx[line[1]]] = line[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity = 1-pairwise_distances(X.T, metric='cosine')\n",
    "user_similarity = 1-pairwise_distances(X, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ntest_book = df_test['book_id'].unique()\\ntest_user = df_test['user_id'].unique()\\n#check if new users\\ncount_new_book = 0\\ncount_new_user = 0\\nfor book in test_book:\\n    if book not in book_ids:\\n        count_new_book+=1\\n\\n\\nfor user in test_user:\\n    if user not in user_ids:\\n        count_new_user+=1\\n\\n\\n#no new books/users!\\nprint(count_new_book,count_new_user)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./data/test.csv')\n",
    "test_book = df_test['book_id'].values\n",
    "test_user = df_test['user_id'].values\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "test_book = df_test['book_id'].unique()\n",
    "test_user = df_test['user_id'].unique()\n",
    "#check if new users\n",
    "count_new_book = 0\n",
    "count_new_user = 0\n",
    "for book in test_book:\n",
    "    if book not in book_ids:\n",
    "        count_new_book+=1\n",
    "\n",
    "\n",
    "for user in test_user:\n",
    "    if user not in user_ids:\n",
    "        count_new_user+=1\n",
    "\n",
    "\n",
    "#no new books/users!\n",
    "print(count_new_book,count_new_user)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_predict(train_data_matrix, item_similarity):\n",
    "    # Calculate the numerator (weighted sum of ratings) for all users and items at once\n",
    "    numerator = train_data_matrix @ item_similarity\n",
    "    \n",
    "    # Calculate the denominator (sum of absolute similarities) for all items at once\n",
    "    denominator = np.abs(item_similarity).sum(axis=1)\n",
    "    \n",
    "    # Avoid division by zero by setting zero denominators to NaN temporarily\n",
    "    denominator = np.where(denominator == 0, np.nan, denominator)\n",
    "    \n",
    "    # Divide each user's weighted sum by the sum of similarities (broadcasting the denominator)\n",
    "    filled_matrix = numerator / denominator\n",
    "    \n",
    "    # Replace NaNs (from zero-denominator cases) with random integer ratings between 1 and 5\n",
    "    filled_matrix = np.where(np.isnan(filled_matrix), np.random.uniform(1, 5, size=filled_matrix.shape), filled_matrix)\n",
    "    \n",
    "    return filled_matrix\n",
    "\n",
    "X_predict_item_filtering = item_based_predict(X, item_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_predict(ratings, user_similarity):\n",
    "    # Copy ratings matrix and replace zero values with NaN for averaging\n",
    "    tmp = ratings.copy()\n",
    "    tmp[tmp == 0] = np.nan\n",
    "    user_average_ratings = np.nanmean(tmp, axis=1)\n",
    "\n",
    "    # Center the ratings by subtracting user averages\n",
    "    centered_ratings = (ratings - user_average_ratings[:, None])\n",
    "    centered_ratings[np.isnan(centered_ratings)] = 0  # Replace NaN with 0 for multiplication\n",
    "    \n",
    "    # Compute the weighted sum of centered ratings using user similarity\n",
    "    numerator = user_similarity @ centered_ratings\n",
    "    \n",
    "    # Compute the denominator (sum of absolute similarities)\n",
    "    denominator = np.abs(user_similarity).sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Avoid division by zero by setting zero denominators to NaN temporarily\n",
    "    denominator = np.where(denominator == 0, np.nan, denominator)\n",
    "    \n",
    "    # Compute the filled matrix by adding back user average ratings\n",
    "    filled_matrix = user_average_ratings[:, None] + numerator / denominator\n",
    "    \n",
    "    # Replace NaNs (from zero-denominator cases) with the user's average rating\n",
    "    filled_matrix = np.where(np.isnan(filled_matrix), user_average_ratings[:, None], filled_matrix)\n",
    "    \n",
    "    # Ensure ratings are within the expected range (0 to 5)\n",
    "    filled_matrix = np.clip(filled_matrix, 0, 5)\n",
    "    \n",
    "    return filled_matrix\n",
    "\n",
    "X_predict_user_filtering = user_based_predict(X, user_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_test = len(df_test)\n",
    "predictions = [0]*nb_test\n",
    "for i in range(nb_test):\n",
    "    predictions[i] = X_predict_user_filtering[user_idx[test_user[i]], book_idx[test_book[i]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7798997581196616"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))\n",
    "\n",
    "\n",
    "rmse(X_predict_user_filtering, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.434392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29362</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29363</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29364</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29365</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29366</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29367 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating\n",
       "0      0.000000\n",
       "1      0.150522\n",
       "2      0.000000\n",
       "3      0.434392\n",
       "4      0.000000\n",
       "...         ...\n",
       "29362  0.000000\n",
       "29363  0.000000\n",
       "29364  0.000000\n",
       "29365  0.000000\n",
       "29366  0.000000\n",
       "\n",
       "[29367 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = {\n",
    "    'rating': predictions\n",
    "}\n",
    "\n",
    "submission = pd.DataFrame(submission)\n",
    "submission.to_csv('./submission.csv')\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
