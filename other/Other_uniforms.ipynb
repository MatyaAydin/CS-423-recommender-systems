{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allow to test init functions similar to the uniform init. However, they all performed worse than the normal uniform.\n",
    "The selection of the function can be made in the last cell by changing the parameter init_star with one of the name present in the second cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_path):\n",
    "    \"\"\"\n",
    "    Prepare data for training and validation.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Prepared data, indices, and metadata.\n",
    "    \"\"\"\n",
    "    df_train = pd.read_csv(data_path + 'train.csv')\n",
    "    book_ids = df_train['book_id'].unique()\n",
    "    user_ids = df_train['user_id'].unique()\n",
    "\n",
    "    n_books = len(book_ids)\n",
    "    n_users = len(user_ids)\n",
    "\n",
    "    book_idx = {ids: i for i, ids in enumerate(book_ids)}\n",
    "    user_idx = {ids: i for i, ids in enumerate(user_ids)}\n",
    "\n",
    "    user_assigned_idx = torch.LongTensor([user_idx[i] for i in df_train['user_id'].values]).to(device)\n",
    "    book_assigned_idx = torch.LongTensor([book_idx[i] for i in df_train['book_id'].values]).to(device)\n",
    "    ratings = torch.FloatTensor(df_train['rating'].values).to(device)\n",
    "\n",
    "    df_train['user_idx'] = df_train['user_id'].map(user_idx)\n",
    "    df_train['book_idx'] = df_train['book_id'].map(book_idx)\n",
    "    train_data, val_data = train_test_split(df_train, test_size=0.01, random_state=42)\n",
    "\n",
    "    return (train_data, val_data, user_assigned_idx, book_assigned_idx, ratings, book_idx, user_idx, n_users, n_books)\n",
    "\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_books, embedding_size, var, init):\n",
    "        super().__init__()\n",
    "        self.P = nn.Embedding(n_users, embedding_size)\n",
    "        self.Q = nn.Embedding(n_books, embedding_size)\n",
    "\n",
    "        if init == 'uniform':\n",
    "            self.P.weight.data.uniform_(0, var)\n",
    "            self.Q.weight.data.uniform_(0, var)\n",
    "        elif init == 'noisy_uniform':\n",
    "            self.P.weight.data.uniform_(-var, var)\n",
    "            self.Q.weight.data.uniform_(-var, var)\n",
    "            noise = torch.randn_like(self.P.weight) * (var / 10)\n",
    "            self.P.weight.data += noise\n",
    "            noise = torch.randn_like(self.Q.weight) * (var / 10)\n",
    "            self.Q.weight.data += noise\n",
    "        elif init == 'clipped_uniform':\n",
    "            self.P.weight.data.uniform_(-var, var)\n",
    "            self.P.weight.data = self.P.weight.data.clamp(-var / 2, var / 2)\n",
    "            self.Q.weight.data.uniform_(-var, var)\n",
    "            self.Q.weight.data = self.Q.weight.data.clamp(-var / 2, var / 2)\n",
    "        elif init == 'lecun_uniform':\n",
    "            fan_in = self.P.embedding_dim\n",
    "            bound = 1 / fan_in**0.5\n",
    "            self.P.weight.data.uniform_(-bound, bound)\n",
    "            self.Q.weight.data.uniform_(-bound, bound)\n",
    "        elif init == 'mean_shifted_uniform':\n",
    "            self.P.weight.data.uniform_(-var, var)\n",
    "            self.Q.weight.data.uniform_(-var, var)\n",
    "            self.P.weight.data += 0.1  # Shift the mean\n",
    "            self.Q.weight.data += 0.1  # Shift the mean\n",
    "\n",
    "    def forward(self, user_id, book_id):\n",
    "        user_vec = self.P(user_id)\n",
    "        book_vec = self.Q(book_id)\n",
    "        return (user_vec * book_vec).sum(1)\n",
    "\n",
    "def train_model(user_assigned_idx, book_assigned_idx, ratings, n_users, n_books, embedding_size=250, var=0.01, init='uniform',\n",
    "                decay=1e-6, lr=1e-4, lambda_=0, n_epochs=1500, verbose=False):\n",
    "    \"\"\"\n",
    "    Train the Matrix Factorization model.\n",
    "\n",
    "    Args:\n",
    "        user_assigned_idx (torch.Tensor): User indices.\n",
    "        book_assigned_idx (torch.Tensor): Book indices.\n",
    "        ratings (torch.Tensor): Ratings.\n",
    "        n_users (int): Number of users.\n",
    "        n_books (int): Number of books.\n",
    "        embedding_size (int): Size of embedding.\n",
    "        var (float): Initialization variance.\n",
    "        init (str): Initialization method ('uniform', 'normal', 'xavier').\n",
    "        decay (float): Weight decay.\n",
    "        lr (float): Learning rate.\n",
    "        lambda_ (float): Regularization parameter.\n",
    "        n_epochs (int): Number of epochs.\n",
    "        verbose (bool): Verbosity flag.\n",
    "\n",
    "    Returns:\n",
    "        MatrixFactorization: Trained model.\n",
    "    \"\"\"\n",
    "    model = MatrixFactorization(n_users, n_books, embedding_size, var, init).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
    "    mse_metric = nn.MSELoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        r_hat = model(user_assigned_idx, book_assigned_idx)\n",
    "        mse = mse_metric(r_hat, ratings)\n",
    "        rmse = torch.sqrt(mse)\n",
    "        loss = mse + lambda_ * (torch.mean(r_hat) - 2.5) ** 2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0 and verbose:\n",
    "            print(f'Epoch {epoch + 1}/{n_epochs}, RMSE: {rmse.item()}, Mean Rating: {torch.mean(r_hat)}')\n",
    "\n",
    "    return model\n",
    "\n",
    "def validate_model(model, user_assigned_idx_val, book_assigned_idx_val, ratings_val):\n",
    "    \"\"\"\n",
    "    Validate the model on unseen data.\n",
    "\n",
    "    Args:\n",
    "        model (MatrixFactorization): Trained model.\n",
    "        user_assigned_idx_val (torch.Tensor): Validation user indices.\n",
    "        book_assigned_idx_val (torch.Tensor): Validation book indices.\n",
    "        ratings_val (torch.Tensor): Validation ratings.\n",
    "\n",
    "    Returns:\n",
    "        tuple: RMSE and mean predicted rating.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    r_hat = model(user_assigned_idx_val, book_assigned_idx_val)\n",
    "    r_hat_clipped = torch.clamp(r_hat, 1, 5)\n",
    "    mse_metric = nn.MSELoss()\n",
    "    err = mse_metric(r_hat_clipped, ratings_val)\n",
    "    rmse = torch.sqrt(err).item()\n",
    "    mean_rating = torch.mean(r_hat_clipped).item()\n",
    "    return rmse, mean_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(model, df_test, user_idx, book_idx, output_path='submission.csv'):\n",
    "    \"\"\"\n",
    "    Generate predictions for the test set and save to CSV.\n",
    "\n",
    "    Args:\n",
    "        model (MatrixFactorization): Trained model.\n",
    "        df_test (pd.DataFrame): Test data.\n",
    "        user_idx (dict): User index mapping.\n",
    "        book_idx (dict): Book index mapping.\n",
    "        output_path (str): Path to save submission file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Submission DataFrame.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_user_assigned_idx = torch.LongTensor([user_idx[i] for i in df_test['user_id'].values]).to(device)\n",
    "    test_book_assigned_idx = torch.LongTensor([book_idx[i] for i in df_test['book_id'].values]).to(device)\n",
    "    predicted_ratings = model(test_user_assigned_idx, test_book_assigned_idx)\n",
    "    predicted_ratings_clipped = torch.clamp(predicted_ratings, 1, 5)\n",
    "    final = [rating.item() for rating in predicted_ratings_clipped]\n",
    "\n",
    "    submission = pd.DataFrame({'id': range(len(df_test)), 'rating': final})\n",
    "    print(f'Saving submission to {output_path}')\n",
    "    submission.to_csv(output_path, index=False)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "data_path = \"./data/\"\n",
    "train_data, val_data, user_assigned_idx, book_assigned_idx, ratings, book_idx, user_idx, n_users, n_books = prepare_data(data_path)\n",
    "\n",
    "# Optimal hyperparameters\n",
    "d_star = 250\n",
    "lr_star = 1e-4\n",
    "var_star = 1e-4\n",
    "decay_star = 1e-6\n",
    "N_EPOCH_STAR = 1500\n",
    "lambda_star = 0\n",
    "init_star = 'uniform'\n",
    "\n",
    "# Train on whole dataset\n",
    "model = train_model(user_assigned_idx, book_assigned_idx, ratings, n_users, n_books, embedding_size=d_star, var=var_star, init=init_star,\n",
    "                decay=decay_star, lr=lr_star, lambda_=lambda_star, n_epochs=N_EPOCH_STAR, verbose=False)\n",
    "\n",
    "# Generate submission\n",
    "df_test = pd.read_csv(data_path + '/test.csv')\n",
    "submission = write_submission(model, df_test, user_idx, book_idx)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
