{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15712, 18905)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load df\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "book_ids = df_train['book_id'].unique()\n",
    "user_ids = df_train['user_id'].unique()\n",
    "\n",
    "nb_books = len(book_ids)\n",
    "nb_users = len(user_ids)\n",
    "\n",
    "nb_books, nb_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_idx = {ids: i for i,ids in enumerate(book_ids)}\n",
    "user_idx = {ids: i for i,ids in enumerate(user_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.zeros((nb_users, nb_books))\n",
    "\n",
    "#inspired from code in week 5 exercise\n",
    "for line in df_train.itertuples():\n",
    "    X[user_idx[line[2]], book_idx[line[1]]] = line[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity = 1-pairwise_distances(X.T, metric='cosine')\n",
    "user_similarity = 1-pairwise_distances(X, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test.csv')\n",
    "test_book = df_test['book_id'].values\n",
    "test_user = df_test['user_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_predict(train_data_matrix, item_similarity):\n",
    "    # Calculate the numerator (weighted sum of ratings) for all users and items at once\n",
    "    numerator = train_data_matrix @ item_similarity\n",
    "    \n",
    "    # Calculate the denominator (sum of absolute similarities) for all items at once\n",
    "    denominator = np.abs(item_similarity).sum(axis=1)\n",
    "    \n",
    "    # Avoid division by zero by setting zero denominators to NaN temporarily\n",
    "    denominator = np.where(denominator == 0, np.nan, denominator)\n",
    "    \n",
    "    # Divide each user's weighted sum by the sum of similarities (broadcasting the denominator)\n",
    "    filled_matrix = numerator / denominator\n",
    "    \n",
    "    # Replace NaNs (from zero-denominator cases) with random integer ratings between 1 and 5\n",
    "    filled_matrix = np.where(np.isnan(filled_matrix), np.random.uniform(1, 5, size=filled_matrix.shape), filled_matrix)\n",
    "    \n",
    "    return filled_matrix\n",
    "\n",
    "X_predict_item_filtering = item_based_predict(X, item_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_predict(ratings, user_similarity):\n",
    "    # Copy ratings matrix and replace zero values with NaN for averaging\n",
    "    tmp = ratings.copy()\n",
    "    tmp[tmp == 0] = np.nan\n",
    "    user_average_ratings = np.nanmean(tmp, axis=1)\n",
    "\n",
    "    # Center the ratings by subtracting user averages\n",
    "    centered_ratings = (ratings - user_average_ratings[:, None])\n",
    "    centered_ratings[np.isnan(centered_ratings)] = 0  # Replace NaN with 0 for multiplication\n",
    "    \n",
    "    # Compute the weighted sum of centered ratings using user similarity\n",
    "    numerator = user_similarity @ centered_ratings\n",
    "    \n",
    "    # Compute the denominator (sum of absolute similarities)\n",
    "    denominator = np.abs(user_similarity).sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Avoid division by zero by setting zero denominators to NaN temporarily\n",
    "    denominator = np.where(denominator == 0, np.nan, denominator)\n",
    "    \n",
    "    # Compute the filled matrix by adding back user average ratings\n",
    "    filled_matrix = user_average_ratings[:, None] + numerator / denominator\n",
    "    \n",
    "    # Replace NaNs (from zero-denominator cases) with the user's average rating\n",
    "    filled_matrix = np.where(np.isnan(filled_matrix), user_average_ratings[:, None], filled_matrix)\n",
    "    \n",
    "    # Ensure ratings are within the expected range (0 to 5)\n",
    "    filled_matrix = np.clip(filled_matrix, 0, 5)\n",
    "    \n",
    "    return filled_matrix\n",
    "\n",
    "X_predict_user_filtering = user_based_predict(X, user_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_test = len(df_test)\n",
    "predictions_item = [0]*nb_test\n",
    "for i in range(nb_test):\n",
    "    predictions_item[i] = X_predict_item_filtering[user_idx[test_user[i]], book_idx[test_book[i]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_test = len(df_test)\n",
    "predictions_user = [0]*nb_test\n",
    "for i in range(nb_test):\n",
    "    predictions_user[i] = X_predict_user_filtering[user_idx[test_user[i]], book_idx[test_book[i]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7798997581196616"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))\n",
    "\n",
    "\n",
    "rmse(X_predict_user_filtering, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_user = np.clip(predictions_user, 0, 5)\n",
    "predictions_item = np.clip(predictions_item, 0, 5)\n",
    "\n",
    "submission_user = pd.DataFrame({\n",
    "            'id':range(len(df_test)),\n",
    "            'rating': predictions_user\n",
    "        })\n",
    "submission_user.to_csv('./submission_user_filtering.csv', index=False)\n",
    "\n",
    "\n",
    "submission_item = pd.DataFrame({\n",
    "            'id':range(len(df_test)),\n",
    "            'rating': predictions_item\n",
    "        })\n",
    "submission_item.to_csv('./submission_item_filtering.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
